{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d2e8b5a-a716-4866-8e73-7c03127e98af",
   "metadata": {},
   "source": [
    "![Notebook Banner](cosmos-predict1_banner.png)\n",
    "\n",
    "## Set Up Docker Login (Executing on A Terminal Locally)\n",
    "\n",
    "Replace <your api key> with your own NGC API Key\n",
    "\n",
    "```bash\n",
    "export NGC_CLI_API_KEY=\"nvapi-xxx\"\n",
    "echo \"$NGC_CLI_API_KEY\" | docker login nvcr.io --username '$oauthtoken' --password-stdin\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbc68f3-4d9a-4322-ac35-7599eeb981e7",
   "metadata": {},
   "source": [
    "## Deploy NIM (Executing on this Jupyter Notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802fad26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to find image 'nvcr.io/nim/nvidia/cosmos-predict1-7b-text2world:1.0.0' locally\n",
      "1.0.0: Pulling from nim/nvidia/cosmos-predict1-7b-text2world\n",
      "54609b48ebc1: Pulling fs layer\n",
      "75f58769314d: Pulling fs layer\n",
      "4f4fb700ef54: Pulling fs layer\n",
      "5a9563dd6b7e: Pulling fs layer\n",
      "e5a680752b35: Pulling fs layer\n",
      "80a4669e4dd4: Pulling fs layer\n",
      "96d91fda4085: Pulling fs layer\n",
      "431ce6d042b2: Pulling fs layer\n",
      "e3fb192c80bb: Pulling fs layer\n",
      "9ab9921d107e: Pulling fs layer\n",
      "62d4750e46d8: Pulling fs layer\n",
      "a3074dfbf063: Pulling fs layer\n",
      "7c931de103d1: Pulling fs layer\n",
      "7f7f4d7e345e: Pulling fs layer\n",
      "428dbc9b0ae2: Pulling fs layer\n",
      "9d954e476889: Pulling fs layer\n",
      "aec8953663b8: Pulling fs layer\n",
      "96ab66c2c93e: Pulling fs layer\n",
      "e7ac6a5dfa8e: Pulling fs layer\n",
      "33e1c8285859: Pulling fs layer\n",
      "a49e681e6b59: Pulling fs layer\n",
      "bd7ad1e267ca: Pulling fs layer\n",
      "8083e2b19e60: Pulling fs layer\n",
      "e5a680752b35: Waiting\n",
      "80a4669e4dd4: Waiting\n",
      "ad268b92b0e9: Pulling fs layer\n",
      "96d91fda4085: Waiting\n",
      "45c8a17276c4: Pulling fs layer\n",
      "f7018f298722: Pulling fs layer\n",
      "926b8fc355ed: Pulling fs layer\n",
      "767d237884ae: Pulling fs layer\n",
      "431ce6d042b2: Waiting\n",
      "13d48b0e4aaa: Pulling fs layer\n",
      "e3fb192c80bb: Waiting\n",
      "252af27023a3: Pulling fs layer\n",
      "61cfbe20cb6f: Pulling fs layer\n",
      "031c50eea2d1: Pulling fs layer\n",
      "9ab9921d107e: Waiting\n",
      "8c1f91e53d8a: Pulling fs layer\n",
      "7f7f4d7e345e: Waiting\n",
      "9ad2b5b1e486: Pulling fs layer\n",
      "08f35301eb48: Pulling fs layer\n",
      "3b7a94a9b4f4: Pulling fs layer\n",
      "67b2e972be48: Pulling fs layer\n",
      "62d4750e46d8: Waiting\n",
      "a3074dfbf063: Waiting\n",
      "7c931de103d1: Waiting\n",
      "bf36ae357666: Pulling fs layer\n",
      "61cfbe20cb6f: Waiting\n",
      "428dbc9b0ae2: Waiting\n",
      "92ff7c96fda9: Pulling fs layer\n",
      "45c8a17276c4: Waiting\n",
      "ecb6d339d990: Pulling fs layer\n",
      "67f996a98e10: Pulling fs layer\n",
      "d3390c92a411: Pulling fs layer\n",
      "24cd2cfb15a5: Pulling fs layer\n",
      "9d954e476889: Waiting\n",
      "031c50eea2d1: Waiting\n",
      "8c1f91e53d8a: Waiting\n",
      "9ad2b5b1e486: Waiting\n",
      "aec8953663b8: Waiting\n",
      "4a7eac37a08e: Pulling fs layer\n",
      "5a9563dd6b7e: Waiting\n",
      "5934cc0acaeb: Pulling fs layer\n",
      "77083ddb1fbc: Pulling fs layer\n",
      "b387e4f85b5a: Pulling fs layer\n",
      "85e7c93fba1f: Pulling fs layer\n",
      "f7018f298722: Waiting\n",
      "7145b7d39638: Pulling fs layer\n",
      "926b8fc355ed: Waiting\n",
      "3b7a94a9b4f4: Waiting\n",
      "c57361a25674: Pulling fs layer\n",
      "c7de36e5cabe: Pulling fs layer\n",
      "767d237884ae: Waiting\n",
      "08f35301eb48: Waiting\n",
      "96ab66c2c93e: Waiting\n",
      "72506404b0d3: Pulling fs layer\n",
      "e7ac6a5dfa8e: Waiting\n",
      "bd7ad1e267ca: Waiting\n",
      "e6c7ecaadaa8: Pulling fs layer\n",
      "e9bb3022357b: Pulling fs layer\n",
      "a49e681e6b59: Waiting\n",
      "b04e414c67e3: Pulling fs layer\n",
      "252af27023a3: Waiting\n",
      "8083e2b19e60: Waiting\n",
      "bf36ae357666: Waiting\n",
      "92ff7c96fda9: Waiting\n",
      "1faca77a27d9: Pulling fs layer\n",
      "e4ef8a2fcaaa: Pulling fs layer\n",
      "959c307cc0c0: Pulling fs layer\n",
      "ad268b92b0e9: Waiting\n",
      "c175e70c2c2d: Pulling fs layer\n",
      "410c62225c3a: Pulling fs layer\n",
      "410c62225c3a: Waiting\n",
      "5934cc0acaeb: Waiting\n",
      "77083ddb1fbc: Waiting\n",
      "d3390c92a411: Waiting\n",
      "33e1c8285859: Waiting\n",
      "c57361a25674: Waiting\n",
      "c7de36e5cabe: Waiting\n",
      "67f996a98e10: Waiting\n",
      "7145b7d39638: Waiting\n",
      "b387e4f85b5a: Waiting\n",
      "24cd2cfb15a5: Waiting\n",
      "72506404b0d3: Waiting\n",
      "e6c7ecaadaa8: Waiting\n",
      "e9bb3022357b: Waiting\n",
      "b04e414c67e3: Waiting\n",
      "1faca77a27d9: Waiting\n",
      "e4ef8a2fcaaa: Waiting\n",
      "4a7eac37a08e: Waiting\n",
      "c175e70c2c2d: Waiting\n",
      "959c307cc0c0: Waiting\n",
      "ecb6d339d990: Waiting\n",
      "13d48b0e4aaa: Waiting\n",
      "85e7c93fba1f: Waiting\n",
      "67b2e972be48: Waiting\n",
      "4f4fb700ef54: Verifying Checksum\n",
      "4f4fb700ef54: Download complete\n",
      "75f58769314d: Verifying Checksum\n",
      "75f58769314d: Download complete\n",
      "e5a680752b35: Download complete\n",
      "54609b48ebc1: Download complete\n",
      "96d91fda4085: Verifying Checksum\n",
      "96d91fda4085: Download complete\n",
      "431ce6d042b2: Download complete\n",
      "e3fb192c80bb: Download complete\n",
      "9ab9921d107e: Download complete\n",
      "62d4750e46d8: Verifying Checksum\n",
      "62d4750e46d8: Download complete\n",
      "54609b48ebc1: Pull complete\n",
      "a3074dfbf063: Verifying Checksum\n",
      "a3074dfbf063: Download complete\n",
      "7c931de103d1: Verifying Checksum\n",
      "7c931de103d1: Download complete\n",
      "5a9563dd6b7e: Verifying Checksum\n",
      "5a9563dd6b7e: Download complete\n",
      "428dbc9b0ae2: Download complete\n",
      "9d954e476889: Verifying Checksum\n",
      "9d954e476889: Download complete\n",
      "aec8953663b8: Verifying Checksum\n",
      "aec8953663b8: Download complete\n",
      "96ab66c2c93e: Verifying Checksum\n",
      "96ab66c2c93e: Download complete\n",
      "75f58769314d: Pull complete\n",
      "4f4fb700ef54: Pull complete\n",
      "7f7f4d7e345e: Verifying Checksum\n",
      "7f7f4d7e345e: Download complete\n",
      "33e1c8285859: Download complete\n",
      "a49e681e6b59: Verifying Checksum\n",
      "a49e681e6b59: Download complete\n",
      "bd7ad1e267ca: Verifying Checksum\n",
      "bd7ad1e267ca: Download complete\n",
      "8083e2b19e60: Verifying Checksum\n",
      "8083e2b19e60: Download complete\n",
      "5a9563dd6b7e: Pull complete\n",
      "e5a680752b35: Pull complete\n",
      "e7ac6a5dfa8e: Verifying Checksum\n",
      "e7ac6a5dfa8e: Download complete\n",
      "45c8a17276c4: Verifying Checksum\n",
      "45c8a17276c4: Download complete\n",
      "f7018f298722: Verifying Checksum\n",
      "f7018f298722: Download complete\n",
      "926b8fc355ed: Verifying Checksum\n",
      "926b8fc355ed: Download complete\n",
      "767d237884ae: Download complete\n",
      "13d48b0e4aaa: Verifying Checksum\n",
      "13d48b0e4aaa: Download complete\n",
      "252af27023a3: Download complete\n",
      "ad268b92b0e9: Verifying Checksum\n",
      "ad268b92b0e9: Download complete\n",
      "031c50eea2d1: Verifying Checksum\n",
      "031c50eea2d1: Download complete\n",
      "8c1f91e53d8a: Verifying Checksum\n",
      "8c1f91e53d8a: Download complete\n",
      "9ad2b5b1e486: Verifying Checksum\n",
      "9ad2b5b1e486: Download complete\n",
      "08f35301eb48: Verifying Checksum\n",
      "08f35301eb48: Download complete\n",
      "3b7a94a9b4f4: Verifying Checksum\n",
      "3b7a94a9b4f4: Download complete\n",
      "67b2e972be48: Verifying Checksum\n",
      "67b2e972be48: Download complete\n",
      "bf36ae357666: Verifying Checksum\n",
      "bf36ae357666: Download complete\n",
      "92ff7c96fda9: Download complete\n",
      "ecb6d339d990: Verifying Checksum\n",
      "ecb6d339d990: Download complete\n",
      "67f996a98e10: Verifying Checksum\n",
      "67f996a98e10: Download complete\n",
      "d3390c92a411: Verifying Checksum\n",
      "d3390c92a411: Download complete\n",
      "24cd2cfb15a5: Verifying Checksum\n",
      "24cd2cfb15a5: Download complete\n",
      "4a7eac37a08e: Download complete\n",
      "5934cc0acaeb: Verifying Checksum\n",
      "5934cc0acaeb: Download complete\n",
      "77083ddb1fbc: Verifying Checksum\n",
      "77083ddb1fbc: Download complete\n",
      "b387e4f85b5a: Verifying Checksum\n",
      "b387e4f85b5a: Download complete\n",
      "85e7c93fba1f: Verifying Checksum\n",
      "85e7c93fba1f: Download complete\n",
      "7145b7d39638: Verifying Checksum\n",
      "7145b7d39638: Download complete\n",
      "c57361a25674: Verifying Checksum\n",
      "c57361a25674: Download complete\n",
      "c7de36e5cabe: Verifying Checksum\n",
      "c7de36e5cabe: Download complete\n",
      "72506404b0d3: Verifying Checksum\n",
      "72506404b0d3: Download complete\n",
      "e6c7ecaadaa8: Download complete\n",
      "e9bb3022357b: Verifying Checksum\n",
      "e9bb3022357b: Download complete\n",
      "b04e414c67e3: Verifying Checksum\n",
      "b04e414c67e3: Download complete\n",
      "1faca77a27d9: Verifying Checksum\n",
      "1faca77a27d9: Download complete\n",
      "e4ef8a2fcaaa: Download complete\n",
      "959c307cc0c0: Verifying Checksum\n",
      "959c307cc0c0: Download complete\n",
      "c175e70c2c2d: Verifying Checksum\n",
      "c175e70c2c2d: Download complete\n",
      "410c62225c3a: Verifying Checksum\n",
      "410c62225c3a: Download complete\n",
      "61cfbe20cb6f: Download complete\n",
      "80a4669e4dd4: Verifying Checksum\n",
      "80a4669e4dd4: Download complete\n",
      "80a4669e4dd4: Pull complete\n",
      "96d91fda4085: Pull complete\n",
      "431ce6d042b2: Pull complete\n",
      "e3fb192c80bb: Pull complete\n",
      "9ab9921d107e: Pull complete\n",
      "62d4750e46d8: Pull complete\n",
      "a3074dfbf063: Pull complete\n",
      "7c931de103d1: Pull complete\n",
      "7f7f4d7e345e: Pull complete\n",
      "428dbc9b0ae2: Pull complete\n",
      "9d954e476889: Pull complete\n",
      "aec8953663b8: Pull complete\n",
      "96ab66c2c93e: Pull complete\n",
      "e7ac6a5dfa8e: Pull complete\n",
      "33e1c8285859: Pull complete\n",
      "a49e681e6b59: Pull complete\n",
      "bd7ad1e267ca: Pull complete\n",
      "8083e2b19e60: Pull complete\n",
      "ad268b92b0e9: Pull complete\n",
      "45c8a17276c4: Pull complete\n",
      "f7018f298722: Pull complete\n",
      "926b8fc355ed: Pull complete\n",
      "767d237884ae: Pull complete\n",
      "13d48b0e4aaa: Pull complete\n",
      "252af27023a3: Pull complete\n",
      "61cfbe20cb6f: Pull complete\n",
      "031c50eea2d1: Pull complete\n",
      "8c1f91e53d8a: Pull complete\n",
      "9ad2b5b1e486: Pull complete\n",
      "08f35301eb48: Pull complete\n",
      "3b7a94a9b4f4: Pull complete\n",
      "67b2e972be48: Pull complete\n",
      "bf36ae357666: Pull complete\n",
      "92ff7c96fda9: Pull complete\n",
      "ecb6d339d990: Pull complete\n",
      "67f996a98e10: Pull complete\n",
      "d3390c92a411: Pull complete\n",
      "24cd2cfb15a5: Pull complete\n",
      "4a7eac37a08e: Pull complete\n",
      "5934cc0acaeb: Pull complete\n",
      "77083ddb1fbc: Pull complete\n",
      "b387e4f85b5a: Pull complete\n",
      "85e7c93fba1f: Pull complete\n",
      "7145b7d39638: Pull complete\n",
      "c57361a25674: Pull complete\n",
      "c7de36e5cabe: Pull complete\n",
      "72506404b0d3: Pull complete\n",
      "e6c7ecaadaa8: Pull complete\n",
      "e9bb3022357b: Pull complete\n",
      "b04e414c67e3: Pull complete\n",
      "1faca77a27d9: Pull complete\n",
      "e4ef8a2fcaaa: Pull complete\n",
      "959c307cc0c0: Pull complete\n",
      "c175e70c2c2d: Pull complete\n",
      "410c62225c3a: Pull complete\n",
      "Digest: sha256:152eac4c3b45a567a126e96acd5d9bbe3f50685a59baf7658f47e1d6b7468e25\n",
      "Status: Downloaded newer image for nvcr.io/nim/nvidia/cosmos-predict1-7b-text2world:1.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7bdaee3486b46708b6cd8fc4c6dbd0fba1b632817cc08f3816e7bb528d74bf1f\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "export NGC_API_KEY=\"nvapi-xxx\"\n",
    "\n",
    "export CONTAINER_NAME=\"cosmos-predict1-7b-text2world\"\n",
    "export IMG_NAME=\"nvcr.io/nim/nvidia/cosmos-predict1-7b-text2world:1.0.0\"\n",
    "\n",
    "# A path on your system to cache the downloaded models\n",
    "export LOCAL_NIM_CACHE=/ephemeral/.cache/nim\n",
    "mkdir -p $LOCAL_NIM_CACHE\n",
    "\n",
    "# Start the NVIDIA NIM for Cosmos\n",
    "docker run -d --rm --name=$CONTAINER_NAME \\\n",
    "    --runtime=nvidia \\\n",
    "    --gpus all \\\n",
    "    --shm-size=16GB \\\n",
    "    -e NGC_API_KEY \\\n",
    "    -v $LOCAL_NIM_CACHE:/opt/nim/.cache \\\n",
    "    -u $(id -u) \\\n",
    "    -p 8000:8000 \\\n",
    "    $IMG_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b41343",
   "metadata": {},
   "source": [
    "### Make Sure the Contianer is Up and Running\n",
    "The following message indicates a successful startup.\n",
    "\n",
    "{'message': 'Starting HTTP Inference server', 'port': 8000, 'workers_count': 1, 'host': '0.0.0.0', 'log_level': 'info', 'SSL': 'disabled'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97dbaf3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================\n",
      "== Triton Inference Server ==\n",
      "=============================\n",
      "\n",
      "NVIDIA Release 25.01 (build 136230209)\n",
      "Triton Server Version 2.54.0\n",
      "\n",
      "Copyright (c) 2018-2024, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the NVIDIA Deep Learning Container License.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n",
      "\n",
      "NOTE: CUDA Forward Compatibility mode ENABLED.\n",
      "  Using CUDA 12.8 driver version 570.86.10 with kernel driver version 535.183.06.\n",
      "  See https://docs.nvidia.com/deploy/cuda-compatibility/ for details.\n",
      "\n",
      "INFO 2025-07-30 13:22:30.589] Starting nimlib 0.8.3 nim_sdk 0.7.6\n",
      "INFO 2025-07-30 13:22:30.589] NIM VERSION:\n",
      "1.0.0\n",
      "INFO 2025-07-30 13:22:30.589] NIM NOTICE:\n",
      "GOVERNING TERMS: The NIM container is governed by the NVIDIA Software License Agreement and Product-Specific Terms for AI Products; and the use of this model is governed by the NVIDIA Open Model License.\n",
      "A copy of theses licenses can be found under /opt/nim/LICENSE.\n",
      "\n",
      "https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-software-license-agreement/\n",
      "https://www.nvidia.com/en-us/agreements/enterprise-software/product-specific-terms-for-ai-products/\n",
      "https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-open-model-license/\n",
      "INFO 2025-07-30 13:22:30.589] NIM banner.txt:\n",
      "The cosmos-predict1-7b-text2world model is licensed under the NVIDIA Open Model License Agreement.\n",
      "\n",
      "https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-open-model-license/\n",
      "\n",
      "INFO 2025-07-30 13:22:34.767] Registered custom profile selectors: [<class 'inference.CosmosProfileSelector'>]\n",
      "INFO 2025-07-30 13:22:34.831] Matched profile_id in manifest from CosmosProfileSelector ad9e1b42331f5453f5b041830cebc89ea65c6fffacdc22962ecb4be3173559f6 with tags: {'llm_precision': 'int8', 'precision': 'bf16', 'profile': 'latency', 'required_ram': '91268055040'}\n",
      "INFO 2025-07-30 13:22:34.831] Using the profile selected by the profile selector: ad9e1b42331f5453f5b041830cebc89ea65c6fffacdc22962ecb4be3173559f6\n",
      "INFO 2025-07-30 13:22:34.831] Downloading manifest profile: ad9e1b42331f5453f5b041830cebc89ea65c6fffacdc22962ecb4be3173559f6\n",
      "INFO 2025-07-30 13:22:34.835 builder.rs:66] ngc configured with api_loc: api.ngc.nvidia.com auth_loc: authn.nvidia.com scheme: https\n",
      "INFO 2025-07-30 13:22:35.607 tokio.rs:812] Downloaded filename: model.onnx to blob: \"/opt/nim/.cache/ngc/hub/models--nim--nvidia--cosmos-predict1-7b-text2world/blobs/d81a1a49d13b3eb13b59a7b9079cf127\"\n",
      "INFO 2025-07-30 13:22:35.609 builder.rs:66] ngc configured with api_loc: api.ngc.nvidia.com auth_loc: authn.nvidia.com scheme: https\n",
      "INFO 2025-07-30 13:22:36.236 tokio.rs:812] Downloaded filename: tokenizer.json to blob: \"/opt/nim/.cache/ngc/hub/models--nim--nvidia--cosmos-predict1-7b-text2world/blobs/56a9f16c4a6e76b23548c1ac20116ec2\"\n",
      "INFO 2025-07-30 13:22:36.238 builder.rs:66] ngc configured with api_loc: api.ngc.nvidia.com auth_loc: authn.nvidia.com scheme: https\n",
      "INFO 2025-07-30 13:22:36.929 tokio.rs:812] Downloaded filename: tokenizer.json to blob: \"/opt/nim/.cache/ngc/hub/models--nim--nvidia--cosmos-predict1-7b-text2world/blobs/470d7c27fc459f1ddad233a7a3537cd5\"\n",
      "INFO 2025-07-30 13:22:36.930 builder.rs:66] ngc configured with api_loc: api.ngc.nvidia.com auth_loc: authn.nvidia.com scheme: https\n",
      "INFO 2025-07-30 13:23:52.825 tokio.rs:812] Downloaded filename: nemo.tar to blob: \"/opt/nim/.cache/ngc/hub/models--nim--nvidia--cosmos-predict1-7b-text2world/blobs/9c816e4cda6e7180f7c60420e5081cc8-63\"\n",
      "INFO 2025-07-30 13:23:52.832 builder.rs:66] ngc configured with api_loc: api.ngc.nvidia.com auth_loc: authn.nvidia.com scheme: https\n",
      "INFO 2025-07-30 13:23:53.470 tokio.rs:812] Downloaded filename: tokenizer_config.json to blob: \"/opt/nim/.cache/ngc/hub/models--nim--nvidia--cosmos-predict1-7b-text2world/blobs/e5add312bce72496f9f7fc1ef936d4e0\"\n",
      "INFO 2025-07-30 13:23:53.471 builder.rs:66] ngc configured with api_loc: api.ngc.nvidia.com auth_loc: authn.nvidia.com scheme: https\n",
      "INFO 2025-07-30 13:23:54.126 tokio.rs:812] Downloaded filename: tokenizer_config.json to blob: \"/opt/nim/.cache/ngc/hub/models--nim--nvidia--cosmos-predict1-7b-text2world/blobs/f6dcfdf7811a345450ee541012b07f8e\"\n",
      "INFO 2025-07-30 13:23:55.032 builder.rs:66] ngc configured with api_loc: api.ngc.nvidia.com auth_loc: authn.nvidia.com scheme: https\n",
      "INFO 2025-07-30 13:23:55.643 tokio.rs:812] Downloaded filename: preprocessor_config.json to blob: \"/opt/nim/.cache/ngc/hub/models--nim--nvidia--cosmos-predict1-7b-text2world/blobs/a3c77d4395235165a5fbcedd428ee718\"\n",
      "INFO 2025-07-30 13:23:55.644 builder.rs:66] ngc configured with api_loc: api.ngc.nvidia.com auth_loc: authn.nvidia.com scheme: https\n",
      "INFO 2025-07-30 13:23:56.654 tokio.rs:812] Downloaded filename: lora/adapter_model.safetensors to blob: \"/opt/nim/.cache/ngc/hub/models--nim--nvidia--cosmos-predict1-7b-text2world/blobs/9381c51ac04e1da9f5c7710ad6fca0df\"\n",
      "INFO 2025-07-30 13:23:56.725 builder.rs:66] ngc configured with api_loc: api.ngc.nvidia.com auth_loc: authn.nvidia.com scheme: https\n",
      "INFO 2025-07-30 13:23:59.027 tokio.rs:812] Downloaded filename: config.json to blob: \"/opt/nim/.cache/ngc/hub/models--nim--nvidia--cosmos-predict1-7b-text2world/blobs/ca4815bcfb3b61b8e5e1fd9368ca14fa\"\n",
      "INFO 2025-07-30 13:23:59.494 builder.rs:66] ngc configured with api_loc: api.ngc.nvidia.com auth_loc: authn.nvidia.com scheme: https\n",
      "INFO 2025-07-30 13:24:00.064 tokio.rs:812] Downloaded filename: special_tokens_map.json to blob: \"/opt/nim/.cache/ngc/hub/models--nim--nvidia--cosmos-predict1-7b-text2world/blobs/673287252c2fe498843bea7e3b938b85\"\n",
      "INFO 2025-07-30 13:24:00.069 builder.rs:66] ngc configured with api_loc: api.ngc.nvidia.com auth_loc: authn.nvidia.com scheme: https\n",
      "INFO 2025-07-30 13:24:00.659 tokio.rs:812] Downloaded filename: lora/adapter_config.json to blob: \"/opt/nim/.cache/ngc/hub/models--nim--nvidia--cosmos-predict1-7b-text2world/blobs/5103d1af993f6d301340552f9d4d8cc9\"\n",
      "INFO 2025-07-30 13:24:00.690 builder.rs:66] ngc configured with api_loc: api.ngc.nvidia.com auth_loc: authn.nvidia.com scheme: https\n",
      "INFO 2025-07-30 13:24:01.262 tokio.rs:812] Downloaded filename: special_tokens_map.json to blob: \"/opt/nim/.cache/ngc/hub/models--nim--nvidia--cosmos-predict1-7b-text2world/blobs/233852366cd703082c92685e630fbede\"\n",
      "INFO 2025-07-30 13:24:01.305 builder.rs:66] ngc configured with api_loc: api.ngc.nvidia.com auth_loc: authn.nvidia.com scheme: https\n",
      "INFO 2025-07-30 13:24:01.959 tokio.rs:812] Downloaded filename: spiece.model to blob: \"/opt/nim/.cache/ngc/hub/models--nim--nvidia--cosmos-predict1-7b-text2world/blobs/c6ec65f49bbfb8b2bf014dbafb34dfe0\"\n",
      "INFO 2025-07-30 13:24:02.041 builder.rs:66] ngc configured with api_loc: api.ngc.nvidia.com auth_loc: authn.nvidia.com scheme: https\n",
      "INFO 2025-07-30 13:24:03.323 tokio.rs:812] Downloaded filename: decoder.jit to blob: \"/opt/nim/.cache/ngc/hub/models--nim--nvidia--cosmos-predict1-7b-text2world/blobs/711a1bd0f1520f13512f7c143e092cc2\"\n",
      "INFO 2025-07-30 13:24:03.324 builder.rs:66] ngc configured with api_loc: api.ngc.nvidia.com auth_loc: authn.nvidia.com scheme: https\n",
      "INFO 2025-07-30 13:24:04.388 tokio.rs:812] Downloaded filename: encoder.jit to blob: \"/opt/nim/.cache/ngc/hub/models--nim--nvidia--cosmos-predict1-7b-text2world/blobs/62db38aecaac848376e99edbf4d3668f\"\n",
      "INFO 2025-07-30 13:24:05.299 builder.rs:66] ngc configured with api_loc: api.ngc.nvidia.com auth_loc: authn.nvidia.com scheme: https\n",
      "INFO 2025-07-30 13:24:05.912 tokio.rs:812] Downloaded filename: tokenizer_config.json to blob: \"/opt/nim/.cache/ngc/hub/models--nim--nvidia--cosmos-predict1-7b-text2world/blobs/5d17211ad7a1d4a912c77cb6d332e129\"\n",
      "INFO 2025-07-30 13:24:05.913 builder.rs:66] ngc configured with api_loc: api.ngc.nvidia.com auth_loc: authn.nvidia.com scheme: https\n",
      "INFO 2025-07-30 13:24:19.184 tokio.rs:812] Downloaded filename: rank0.safetensors to blob: \"/opt/nim/.cache/ngc/hub/models--nim--nvidia--cosmos-predict1-7b-text2world/blobs/c1d493c311bd7b721608cd9960176f9d-15\"\n",
      "INFO 2025-07-30 13:24:19.199 builder.rs:66] ngc configured with api_loc: api.ngc.nvidia.com auth_loc: authn.nvidia.com scheme: https\n",
      "INFO 2025-07-30 13:24:19.799 tokio.rs:812] Downloaded filename: model_config.yaml to blob: \"/opt/nim/.cache/ngc/hub/models--nim--nvidia--cosmos-predict1-7b-text2world/blobs/1e75eceee2dd30f8b0f2384602734736\"\n",
      "INFO 2025-07-30 13:24:21.073 builder.rs:66] ngc configured with api_loc: api.ngc.nvidia.com auth_loc: authn.nvidia.com scheme: https\n",
      "INFO 2025-07-30 13:24:21.639 tokio.rs:812] Downloaded filename: special_tokens_map.json to blob: \"/opt/nim/.cache/ngc/hub/models--nim--nvidia--cosmos-predict1-7b-text2world/blobs/36be4dc5ae6835f7e430ae026b71b15d\"\n",
      "INFO 2025-07-30 13:24:21.678 builder.rs:66] ngc configured with api_loc: api.ngc.nvidia.com auth_loc: authn.nvidia.com scheme: https\n",
      "INFO 2025-07-30 13:24:22.437 tokio.rs:812] Downloaded filename: model.onnx to blob: \"/opt/nim/.cache/ngc/hub/models--nim--nvidia--cosmos-predict1-7b-text2world/blobs/2e3ccbb24a7d2c55f935e81ad28edfe3\"\n",
      "INFO 2025-07-30 13:24:22.437 builder.rs:66] ngc configured with api_loc: api.ngc.nvidia.com auth_loc: authn.nvidia.com scheme: https\n",
      "INFO 2025-07-30 13:24:23.026 tokio.rs:812] Downloaded filename: config.json to blob: \"/opt/nim/.cache/ngc/hub/models--nim--nvidia--cosmos-predict1-7b-text2world/blobs/39479ed2353edbe0fd6b3faa7fc8e791\"\n",
      "INFO 2025-07-30 13:24:23.032 builder.rs:66] ngc configured with api_loc: api.ngc.nvidia.com auth_loc: authn.nvidia.com scheme: https\n",
      "INFO 2025-07-30 13:24:23.555 tokio.rs:812] Downloaded filename: mean_std.pt to blob: \"/opt/nim/.cache/ngc/hub/models--nim--nvidia--cosmos-predict1-7b-text2world/blobs/8a652c17093e36007f64229b5d130bb0\"\n",
      "INFO 2025-07-30 13:24:23.627 builder.rs:66] ngc configured with api_loc: api.ngc.nvidia.com auth_loc: authn.nvidia.com scheme: https\n",
      "INFO 2025-07-30 13:24:24.297 tokio.rs:812] Downloaded filename: tokenizer.json to blob: \"/opt/nim/.cache/ngc/hub/models--nim--nvidia--cosmos-predict1-7b-text2world/blobs/30405dd32dc2b963312357bcb24bbe51\"\n",
      "INFO 2025-07-30 13:24:24.373 builder.rs:66] ngc configured with api_loc: api.ngc.nvidia.com auth_loc: authn.nvidia.com scheme: https\n",
      "INFO 2025-07-30 13:24:25.400 tokio.rs:812] Downloaded filename: autoencoder.jit to blob: \"/opt/nim/.cache/ngc/hub/models--nim--nvidia--cosmos-predict1-7b-text2world/blobs/28ce363adad1a015be376e3e6df8d233\"\n",
      "INFO 2025-07-30 13:24:26.926 builder.rs:66] ngc configured with api_loc: api.ngc.nvidia.com auth_loc: authn.nvidia.com scheme: https\n",
      "INFO 2025-07-30 13:24:29.466 tokio.rs:812] Downloaded filename: model.onnx to blob: \"/opt/nim/.cache/ngc/hub/models--nim--nvidia--cosmos-predict1-7b-text2world/blobs/7130209c0f313b99d9b51b8b4c2401ac-2\"\n",
      "INFO 2025-07-30 13:24:29.467 builder.rs:66] ngc configured with api_loc: api.ngc.nvidia.com auth_loc: authn.nvidia.com scheme: https\n",
      "INFO 2025-07-30 13:24:30.033 tokio.rs:812] Downloaded filename: config.json to blob: \"/opt/nim/.cache/ngc/hub/models--nim--nvidia--cosmos-predict1-7b-text2world/blobs/988cc320e7b5b802bbd1bed0e52e4a25\"\n",
      "INFO 2025-07-30 13:24:31.655 builder.rs:66] ngc configured with api_loc: api.ngc.nvidia.com auth_loc: authn.nvidia.com scheme: https\n",
      "INFO 2025-07-30 13:24:32.274 tokio.rs:812] Downloaded filename: tokenizer.json to blob: \"/opt/nim/.cache/ngc/hub/models--nim--nvidia--cosmos-predict1-7b-text2world/blobs/7f685632e95322e351d1a2bbdca5955c\"\n",
      "INFO 2025-07-30 13:24:32.275 builder.rs:66] ngc configured with api_loc: api.ngc.nvidia.com auth_loc: authn.nvidia.com scheme: https\n",
      "INFO 2025-07-30 13:24:59.425 tokio.rs:812] Downloaded filename: rank0.safetensors to blob: \"/opt/nim/.cache/ngc/hub/models--nim--nvidia--cosmos-predict1-7b-text2world/blobs/5f74e178da9f45ad1aecccadc06a27b7-28\"\n",
      "INFO 2025-07-30 13:24:59.472 builder.rs:66] ngc configured with api_loc: api.ngc.nvidia.com auth_loc: authn.nvidia.com scheme: https\n",
      "INFO 2025-07-30 13:25:21.556 tokio.rs:812] Downloaded filename: extra_data.bin to blob: \"/opt/nim/.cache/ngc/hub/models--nim--nvidia--cosmos-predict1-7b-text2world/blobs/a94c0de65d41f65969288f5ac0d1d4b5-20\"\n",
      "INFO 2025-07-30 13:25:22.047 builder.rs:66] ngc configured with api_loc: api.ngc.nvidia.com auth_loc: authn.nvidia.com scheme: https\n",
      "INFO 2025-07-30 13:25:22.679 tokio.rs:812] Downloaded filename: spiece.model to blob: \"/opt/nim/.cache/ngc/hub/models--nim--nvidia--cosmos-predict1-7b-text2world/blobs/080f2c57483f2f6236a846997b2a0298\"\n",
      "INFO 2025-07-30 13:25:22.744 builder.rs:66] ngc configured with api_loc: api.ngc.nvidia.com auth_loc: authn.nvidia.com scheme: https\n",
      "INFO 2025-07-30 13:25:23.443 tokio.rs:812] Downloaded filename: blocklist.tar to blob: \"/opt/nim/.cache/ngc/hub/models--nim--nvidia--cosmos-predict1-7b-text2world/blobs/313c2da2c6d5058b02cae503737cce5c\"\n",
      "INFO 2025-07-30 13:25:23.444] Using the workspace specified during init: /opt/nim/workspace\n",
      "INFO 2025-07-30 13:25:23.444] Creating workspace at /opt/nim/workspace\n",
      "INFO 2025-07-30 13:25:23.444] Materializing workspace to: /opt/nim/workspace\n",
      "INFO 2025-07-30 13:25:27.330] Results of triton model repository search: {'model_repo': {'t5': {'has_config': True, 'has_version_directory': True}, 'diffusion': {'has_version_directory': True, 'has_config': True}, 'detect_faces': {'has_config': True, 'has_version_directory': True}, 't5_tokenizer': {'has_version_directory': True, 'has_config': True}, 'ensemble': {'has_version_directory': True, 'has_config': True}, 'prompt_upsampler': {'has_config': True, 'has_version_directory': True}, 'aegis_filter': {'has_version_directory': True, 'has_config': True}, 'siglip_filter': {'has_version_directory': True, 'has_config': True}, 'siglip_filter_processor': {'has_version_directory': True, 'has_config': True}, 'blocklist_filter': {'has_version_directory': True, 'has_config': True}, 'face_blur': {'has_version_directory': True, 'has_config': True}}}\n",
      "INFO 2025-07-30 13:25:27.331] Starting Triton server: /opt/nim/.venv/lib/python3.12/site-packages/nimlib/triton_start.sh -m /opt/nim/workspace/model_repo -d - -h 8083 -p 8002 -l 0 -x -\n",
      "INFO 2025-07-30 13:25:27.331] Starting NIM inference server\n",
      "INFO 2025-07-30 13:25:30.429] Running: tritonserver --model-repository /opt/nim/workspace/model_repo --http-port 8083 --metrics-port 8002  --log-verbose 0\n",
      "INFO 2025-07-30 13:25:42.186] INFO 2025-07-30 13:25:42.186] Initializing Aegis\n",
      "INFO 2025-07-30 13:25:47.676] INFO 2025-07-30 13:25:47.676] Initializing Blocklist\n",
      "INFO 2025-07-30 13:25:47.845] INFO 2025-07-30 13:25:47.844] Initializing Blocklist\n",
      "INFO 2025-07-30 13:26:16.980] [TensorRT-LLM] TensorRT-LLM version: 0.18.0.dev2025022500\n",
      "INFO 2025-07-30 13:26:22.070] INFO 2025-07-30 13:26:22.070] Blocklist initializing completed\n",
      "INFO 2025-07-30 13:26:22.081] INFO 2025-07-30 13:26:22.081] Blocklist initializing completed\n",
      "INFO 2025-07-30 13:27:19.689] INFO 2025-07-30 13:27:19.689] Initializing Upsampler\n",
      "INFO 2025-07-30 13:27:47.831] [TensorRT-LLM] TensorRT-LLM version: 0.18.0.dev2025022500\n",
      "INFO 2025-07-30 13:28:26.387] [TensorRT-LLM] TensorRT-LLM version: 0.18.0.dev2025022500\n",
      "INFO 2025-07-30 13:28:26.515] [TensorRT-LLM][INFO] Refreshed the MPI local session\n",
      "INFO 2025-07-30 13:28:26.564] [TensorRT-LLM][INFO] Engine version 0.18.0.dev2025022500 found in the config file, assuming engine(s) built by new builder API.\n",
      "INFO 2025-07-30 13:28:26.564] [TensorRT-LLM][INFO] Refreshed the MPI local session\n",
      "INFO 2025-07-30 13:28:26.565] [TensorRT-LLM][INFO] MPI size: 1, MPI local size: 1, rank: 0\n",
      "INFO 2025-07-30 13:28:26.568] [TensorRT-LLM][INFO] Rank 0 is using GPU 0\n",
      "INFO 2025-07-30 13:28:26.830] [TensorRT-LLM][INFO] TRTGptModel maxNumSequences: 1\n",
      "INFO 2025-07-30 13:28:26.830] [TensorRT-LLM][INFO] TRTGptModel maxBatchSize: 1\n",
      "INFO 2025-07-30 13:28:26.830] [TensorRT-LLM][INFO] TRTGptModel maxBeamWidth: 1\n",
      "INFO 2025-07-30 13:28:26.830] [TensorRT-LLM][INFO] TRTGptModel maxSequenceLen: 4096\n",
      "INFO 2025-07-30 13:28:26.830] [TensorRT-LLM][INFO] TRTGptModel maxDraftLen: 0\n",
      "INFO 2025-07-30 13:28:26.830] [TensorRT-LLM][INFO] TRTGptModel mMaxAttentionWindowSize: (4096) * 32\n",
      "INFO 2025-07-30 13:28:26.830] [TensorRT-LLM][INFO] TRTGptModel enableTrtOverlap: 0\n",
      "INFO 2025-07-30 13:28:26.830] [TensorRT-LLM][INFO] TRTGptModel normalizeLogProbs: 0\n",
      "INFO 2025-07-30 13:28:26.830] [TensorRT-LLM][INFO] TRTGptModel maxNumTokens: 1024\n",
      "INFO 2025-07-30 13:28:26.830] [TensorRT-LLM][INFO] TRTGptModel maxInputLen: 4095  = maxSequenceLen - 1 since chunked context is enabled\n",
      "INFO 2025-07-30 13:28:26.830] [TensorRT-LLM][INFO] TRTGptModel If model type is encoder, maxInputLen would be reset in trtEncoderModel to maxInputLen: 4096 = maxSequenceLen.\n",
      "INFO 2025-07-30 13:28:26.830] [TensorRT-LLM][INFO] Capacity Scheduler Policy: GUARANTEED_NO_EVICT\n",
      "INFO 2025-07-30 13:28:26.830] [TensorRT-LLM][INFO] Context Chunking Scheduler Policy: None\n",
      "INFO 2025-07-30 13:28:30.016] [TensorRT-LLM][INFO] Loaded engine size: 6707 MiB\n",
      "INFO 2025-07-30 13:28:33.711] [TensorRT-LLM][INFO] This engine can stream its weights. Please use setWeightStreamingBudgetV2() to enable it during execution.\n",
      "INFO 2025-07-30 13:28:33.711] [TensorRT-LLM][INFO] - Minimum budget: 0 bytes\n",
      "INFO 2025-07-30 13:28:33.711] [TensorRT-LLM][INFO] - Maximum budget: 7009356800 bytes\n",
      "INFO 2025-07-30 13:28:33.712] [TensorRT-LLM][INFO] Inspecting the engine to identify potential runtime issues...\n",
      "INFO 2025-07-30 13:28:33.712] [TensorRT-LLM][INFO] The profiling verbosity of the engine does not allow this analysis to proceed. Re-build the engine with 'detailed' profiling verbosity to get more diagnostics.\n",
      "INFO 2025-07-30 13:28:33.712] [TensorRT-LLM][INFO] Set gpu weights percent to 0.500000, which is 3504678400 bytes. Valid range: 0 bytes - 7009356800 bytes.\n",
      "INFO 2025-07-30 13:28:33.719] [TensorRT-LLM][INFO] [MemUsageChange] Allocated 436.12 MiB for execution context memory.\n",
      "INFO 2025-07-30 13:28:33.719] [TensorRT-LLM][INFO] gatherContextLogits: 0\n",
      "INFO 2025-07-30 13:28:33.720] [TensorRT-LLM][INFO] gatherGenerationLogits: 0\n",
      "INFO 2025-07-30 13:28:39.515] [TensorRT-LLM][INFO] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +3342, now: CPU 6684, GPU 3344 (MiB)\n",
      "INFO 2025-07-30 13:28:39.737] [TensorRT-LLM][INFO] [MemUsageChange] Allocated 162.57 KB GPU memory for runtime buffers.\n",
      "INFO 2025-07-30 13:28:39.742] [TensorRT-LLM][INFO] [MemUsageChange] Allocated 424.96 KB GPU memory for decoder.\n",
      "INFO 2025-07-30 13:28:39.742] [TensorRT-LLM][INFO] Memory usage when calculating max tokens in paged kv cache: total: 79.15 GiB, available: 65.46 GiB\n",
      "INFO 2025-07-30 13:28:39.742] [TensorRT-LLM][INFO] Maximum kv-cache token overridden by configuration as '2392'.\n",
      "INFO 2025-07-30 13:28:39.742] [TensorRT-LLM][INFO] Number of blocks in KV cache primary pool: 75\n",
      "INFO 2025-07-30 13:28:39.742] [TensorRT-LLM][INFO] Number of blocks in KV cache secondary pool: 0, onboard blocks to primary memory before reuse: true\n",
      "INFO 2025-07-30 13:28:39.742] [TensorRT-LLM][WARNING] maxAttentionWindow and maxSequenceLen are too large for at least one sequence to fit in kvCache. they are reduced to 2369\n",
      "INFO 2025-07-30 13:28:39.742] [TensorRT-LLM][WARNING] maxInputLen is reduced to 2368\n",
      "INFO 2025-07-30 13:28:39.746] [TensorRT-LLM][INFO] Number of tokens per block: 32.\n",
      "INFO 2025-07-30 13:28:39.746] [TensorRT-LLM][INFO] [MemUsageChange] Allocated 1.17 GiB for max tokens in paged KV cache (2400).\n",
      "INFO 2025-07-30 13:28:39.748] INFO 2025-07-30 13:28:39.748] Aegis initializing completed. BS 1 SL=2392\n",
      "INFO 2025-07-30 13:29:49.084] INFO 2025-07-30 13:29:49.083] Spawning diffusion processes for devices [0]\n",
      "INFO 2025-07-30 13:29:49.084] INFO 2025-07-30 13:29:49.083] Loading diffusion model\n",
      "INFO 2025-07-30 13:29:49.401] [NeMo I 2025-07-30 13:29:49 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "INFO 2025-07-30 13:29:49.401] [NeMo I 2025-07-30 13:29:49 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "INFO 2025-07-30 13:29:49.401] [NeMo I 2025-07-30 13:29:49 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "INFO 2025-07-30 13:29:49.402] [NeMo I 2025-07-30 13:29:49 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "INFO 2025-07-30 13:29:49.402] [NeMo I 2025-07-30 13:29:49 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "INFO 2025-07-30 13:29:49.402] [NeMo I 2025-07-30 13:29:49 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "INFO 2025-07-30 13:29:49.402] [NeMo I 2025-07-30 13:29:49 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "INFO 2025-07-30 13:29:49.402] [NeMo I 2025-07-30 13:29:49 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "INFO 2025-07-30 13:29:49.402] [NeMo I 2025-07-30 13:29:49 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "INFO 2025-07-30 13:29:49.402] [NeMo I 2025-07-30 13:29:49 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "INFO 2025-07-30 13:29:49.402] [NeMo I 2025-07-30 13:29:49 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "INFO 2025-07-30 13:29:49.402] [NeMo I 2025-07-30 13:29:49 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "INFO 2025-07-30 13:29:49.402] [NeMo I 2025-07-30 13:29:49 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "INFO 2025-07-30 13:29:49.402] [NeMo I 2025-07-30 13:29:49 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "INFO 2025-07-30 13:29:49.402] [NeMo I 2025-07-30 13:29:49 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "INFO 2025-07-30 13:29:49.402] [NeMo I 2025-07-30 13:29:49 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "INFO 2025-07-30 13:29:49.402] [NeMo I 2025-07-30 13:29:49 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "INFO 2025-07-30 13:29:49.402] [NeMo I 2025-07-30 13:29:49 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "INFO 2025-07-30 13:29:50.266] [NeMo I 2025-07-30 13:29:50 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 7764674688\n",
      "INFO 2025-07-30 13:31:10.687] [TensorRT-LLM] TensorRT-LLM version: 0.18.0.dev2025022500\n",
      "INFO 2025-07-30 13:31:10.831] [TensorRT-LLM][INFO] Refreshed the MPI local session\n",
      "INFO 2025-07-30 13:31:10.864] [TensorRT-LLM][INFO] Engine version 0.18.0.dev2025022500 found in the config file, assuming engine(s) built by new builder API.\n",
      "INFO 2025-07-30 13:31:10.865] [TensorRT-LLM][INFO] Refreshed the MPI local session\n",
      "INFO 2025-07-30 13:31:10.865] [TensorRT-LLM][INFO] MPI size: 1, MPI local size: 1, rank: 0\n",
      "INFO 2025-07-30 13:31:10.866] [TensorRT-LLM][INFO] Rank 0 is using GPU 0\n",
      "INFO 2025-07-30 13:31:11.072] [TensorRT-LLM][INFO] TRTGptModel maxNumSequences: 1\n",
      "INFO 2025-07-30 13:31:11.073] [TensorRT-LLM][INFO] TRTGptModel maxBatchSize: 1\n",
      "INFO 2025-07-30 13:31:11.073] [TensorRT-LLM][INFO] TRTGptModel maxBeamWidth: 1\n",
      "INFO 2025-07-30 13:31:11.073] [TensorRT-LLM][INFO] TRTGptModel maxSequenceLen: 131072\n",
      "INFO 2025-07-30 13:31:11.073] [TensorRT-LLM][INFO] TRTGptModel maxDraftLen: 0\n",
      "INFO 2025-07-30 13:31:11.073] [TensorRT-LLM][INFO] TRTGptModel mMaxAttentionWindowSize: (131072) * 40\n",
      "INFO 2025-07-30 13:31:11.073] [TensorRT-LLM][INFO] TRTGptModel enableTrtOverlap: 0\n",
      "INFO 2025-07-30 13:31:11.073] [TensorRT-LLM][INFO] TRTGptModel normalizeLogProbs: 0\n",
      "INFO 2025-07-30 13:31:11.073] [TensorRT-LLM][INFO] TRTGptModel maxNumTokens: 1024\n",
      "INFO 2025-07-30 13:31:11.073] [TensorRT-LLM][INFO] TRTGptModel maxInputLen: 131071  = maxSequenceLen - 1 since chunked context is enabled\n",
      "INFO 2025-07-30 13:31:11.073] [TensorRT-LLM][INFO] TRTGptModel If model type is encoder, maxInputLen would be reset in trtEncoderModel to maxInputLen: 131072 = maxSequenceLen.\n",
      "INFO 2025-07-30 13:31:11.073] [TensorRT-LLM][INFO] Capacity Scheduler Policy: GUARANTEED_NO_EVICT\n",
      "INFO 2025-07-30 13:31:11.073] [TensorRT-LLM][INFO] Context Chunking Scheduler Policy: None\n",
      "INFO 2025-07-30 13:31:17.180] [TensorRT-LLM][INFO] Loaded engine size: 13039 MiB\n",
      "INFO 2025-07-30 13:31:19.265] [TensorRT-LLM][INFO] Inspecting the engine to identify potential runtime issues...\n",
      "INFO 2025-07-30 13:31:19.265] [TensorRT-LLM][INFO] The profiling verbosity of the engine does not allow this analysis to proceed. Re-build the engine with 'detailed' profiling verbosity to get more diagnostics.\n",
      "INFO 2025-07-30 13:31:19.266] [TensorRT-LLM][INFO] [MemUsageChange] Allocated 142.01 MiB for execution context memory.\n",
      "INFO 2025-07-30 13:31:19.266] [TensorRT-LLM][INFO] gatherContextLogits: 0\n",
      "INFO 2025-07-30 13:31:19.266] [TensorRT-LLM][INFO] gatherGenerationLogits: 0\n",
      "INFO 2025-07-30 13:31:19.575] [TensorRT-LLM][INFO] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 13028 (MiB)\n",
      "INFO 2025-07-30 13:31:19.758] [TensorRT-LLM][INFO] [MemUsageChange] Allocated 3.25 MB GPU memory for runtime buffers.\n",
      "INFO 2025-07-30 13:31:19.763] [TensorRT-LLM][INFO] [MemUsageChange] Allocated 3.30 MB GPU memory for decoder.\n",
      "INFO 2025-07-30 13:31:19.763] [TensorRT-LLM][INFO] Memory usage when calculating max tokens in paged kv cache: total: 79.15 GiB, available: 30.49 GiB\n",
      "INFO 2025-07-30 13:31:19.763] [TensorRT-LLM][INFO] Maximum kv-cache token overridden by configuration as '1024'.\n",
      "INFO 2025-07-30 13:31:19.763] [TensorRT-LLM][INFO] Number of blocks in KV cache primary pool: 32\n",
      "INFO 2025-07-30 13:31:19.763] [TensorRT-LLM][INFO] Number of blocks in KV cache secondary pool: 0, onboard blocks to primary memory before reuse: true\n",
      "INFO 2025-07-30 13:31:19.763] [TensorRT-LLM][WARNING] maxAttentionWindow and maxSequenceLen are too large for at least one sequence to fit in kvCache. they are reduced to 993\n",
      "INFO 2025-07-30 13:31:19.763] [TensorRT-LLM][WARNING] maxInputLen is reduced to 992\n",
      "INFO 2025-07-30 13:31:19.763] [TensorRT-LLM][INFO] Number of tokens per block: 32.\n",
      "INFO 2025-07-30 13:31:19.764] [TensorRT-LLM][INFO] [MemUsageChange] Allocated 0.16 GiB for max tokens in paged KV cache (1024).\n",
      "INFO 2025-07-30 13:31:20.307] INFO 2025-07-30 13:31:20.307] Upsampler initializing completed. BS 1 SL=1024\n",
      "INFO 2025-07-30 13:33:00.414] Loading distributed checkpoint with TensorStoreLoadShardedStrategy\n",
      "INFO 2025-07-30 13:33:00.414] Loading distributed checkpoint directly on the GPU\n",
      "INFO 2025-07-30 13:33:00.414] INFO 2025-07-30 13:33:00.413] Initialized diffusion model in 365.18246744399994s\n",
      "INFO 2025-07-30 13:33:02.623] Serving endpoints:\n",
      "  0.0.0.0:8000/v1/health/live (GET)\n",
      "  0.0.0.0:8000/v1/health/ready (GET)\n",
      "  0.0.0.0:8000/v1/metrics (GET)\n",
      "  0.0.0.0:8000/v1/license (GET)\n",
      "  0.0.0.0:8000/v1/metadata (GET)\n",
      "  0.0.0.0:8000/v1/manifest (GET)\n",
      "  0.0.0.0:8000/v1/infer (POST)\n",
      "INFO 2025-07-30 13:33:02.623] {'message': 'Starting HTTP Inference server', 'port': 8000, 'workers_count': 1, 'host': '0.0.0.0', 'log_level': 'info', 'SSL': 'disabled'}\n"
     ]
    }
   ],
   "source": [
    "!docker logs cosmos-predict1-7b-text2world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1f6a6d3-8572-4c6f-9eea-c4205aabffa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP/1.1 200 OK\n",
      "\u001b[1mdate\u001b[0m: Wed, 30 Jul 2025 13:41:08 GMT\n",
      "\u001b[1mserver\u001b[0m: uvicorn\n",
      "\u001b[1mcontent-length\u001b[0m: 55\n",
      "\u001b[1mcontent-type\u001b[0m: application/json\n",
      "\n",
      "{\"description\":\"Triton liveness check\",\"status\":\"live\"}"
     ]
    }
   ],
   "source": [
    "!curl -i -X GET 'http://0.0.0.0:8000/v1/health/live'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9d448d-104d-4bce-b29e-84337a96fd9a",
   "metadata": {},
   "source": [
    "## Start Inferencing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f06696d-a54f-49c1-a798-53c871671160",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "422 Client Error: Unprocessable Entity for url: http://0.0.0.0:8000/v1/infer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 19\u001b[0m\n\u001b[1;32m      4\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst person view from a camera in a car driving down a two lane neighborhood street, \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mviewed from the dashcam as we drive down the street. \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe camera faces forward. There are nice houses and sidewalks \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min this suburban area with green grass front yards and flower gardens and large oak trees. \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is a rainy day and there are grey clouds overhead. \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe road has puddles on it, reflecting the sky overhead. The windshield wipers flash by.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://0.0.0.0:8000/v1/infer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(prompt\u001b[38;5;241m=\u001b[39mprompt),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     }\n\u001b[1;32m     18\u001b[0m )\n\u001b[0;32m---> 19\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb64_video\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m video_bytes \u001b[38;5;241m=\u001b[39m base64\u001b[38;5;241m.\u001b[39mb64decode(data)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py:1026\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1022\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1023\u001b[0m     )\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 422 Client Error: Unprocessable Entity for url: http://0.0.0.0:8000/v1/infer"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import base64\n",
    "\n",
    "prompt = \"first person view from a camera in a car driving down a two lane neighborhood street, \" \\\n",
    "    \"viewed from the dashcam as we drive down the street. \" \\\n",
    "    \"The camera faces forward. There are nice houses and sidewalks \" \\\n",
    "    \"in this suburban area with green grass front yards and flower gardens and large oak trees. \" \\\n",
    "    \"It is a rainy day and there are grey clouds overhead. \" \\\n",
    "    \"The road has puddles on it, reflecting the sky overhead. The windshield wipers flash by.\"\n",
    "\n",
    "response = requests.post(\n",
    "    \"http://0.0.0.0:8000/v1/infer\",\n",
    "    json=dict(prompt=prompt),\n",
    "    headers={\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    ")\n",
    "response.raise_for_status()\n",
    "\n",
    "data = response.json().get(\"b64_video\")\n",
    "video_bytes = base64.b64decode(data)\n",
    "\n",
    "with open(\"video.mp4\", \"wb\") as video_file:\n",
    "    video_file.write(video_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab73cf0-cb0f-434e-a7ff-71f204f121ca",
   "metadata": {},
   "source": [
    "## Stop the Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34f54a0-334b-4033-9ede-5fc84dd72016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n",
      "Error response from daemon: No such container: Llama3-8B-Instruct\n"
     ]
    }
   ],
   "source": [
    "!docker ps -a && \\\n",
    "docker stop cosmos-predict1-7b-text2world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044a6fb4-0c7d-453e-bd5c-52a66c65b1e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
