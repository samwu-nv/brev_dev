{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d2e8b5a-a716-4866-8e73-7c03127e98af",
   "metadata": {},
   "source": [
    "![Notebook Banner](llama3_banner.png)\n",
    "\n",
    "## Set Up Docker Login (Executing on A Terminal Locally)\n",
    "\n",
    "Replace <your api key> with your own NGC API Key\n",
    "\n",
    "```bash\n",
    "export NGC_CLI_API_KEY=\"nvapi-xxx\"\n",
    "echo \"$NGC_CLI_API_KEY\" | docker login nvcr.io --username '$oauthtoken' --password-stdin\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbc68f3-4d9a-4322-ac35-7599eeb981e7",
   "metadata": {},
   "source": [
    "## Deploy NIM (Executing on this Jupyter Notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cf8bc0-2d24-4ffd-a737-b54de30eef9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f64fed02a76bd744005beefea1a8a1f2707b95fb0eaff03e3294d6ec19f7adb7\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "export NGC_API_KEY=\"nvapi-xxx\"\n",
    "\n",
    "export CONTAINER_NAME=\"Llama3-8B-Instruct\"\n",
    "export IMG_NAME=\"nvcr.io/nim/meta/llama3-8b-instruct:1.0.3\"\n",
    "export LOCAL_NIM_CACHE=~/.cache/nim\n",
    "mkdir -p $LOCAL_NIM_CACHE\n",
    "\n",
    "docker run -d --rm --name=$CONTAINER_NAME \\\n",
    "    --runtime=nvidia \\\n",
    "    --gpus all \\\n",
    "    --shm-size=16GB \\\n",
    "    -e NGC_API_KEY \\\n",
    "    -v $LOCAL_NIM_CACHE:/opt/nim/.cache \\\n",
    "    -u $(id -u) \\\n",
    "    -p 8000:8000 \\\n",
    "    $IMG_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9d448d-104d-4bce-b29e-84337a96fd9a",
   "metadata": {},
   "source": [
    "## Start Inferencing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4efb19a8-63dc-413e-8e04-fe738664605c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in ./.local/lib/python3.10/site-packages (1.97.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.local/lib/python3.10/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "\u001b[33mWARNING: Error parsing dependencies of devscripts: Invalid version: '2.22.1ubuntu1'\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f06696d-a54f-49c1-a798-53c871671160",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There once was a GPU so fine,\n",
      "Whose computing powers were truly divine.\n",
      "It processed with zest,\n",
      "Complex tasks with the best,\n",
      "And made calculations that were sublime."
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    # base_url='https://integrate.api.nvidia.com/v1',\n",
    "    base_url='http://0.0.0.0:8000/v1',\n",
    "    api_key=\"$NGC_API_KEY\"\n",
    ")\n",
    "completion = client.chat.completions.create(\n",
    "    model='meta/llama3-8b-instruct',\n",
    "    messages=[{\"role\":\"user\", \"content\":\"Write a limerick about the wonders of GPU computing.\"}],\n",
    "    temperature=0.5,\n",
    "    top_p=1,\n",
    "    max_tokens=1024,\n",
    "    stream=True\n",
    ")\n",
    "for chunk in completion:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab73cf0-cb0f-434e-a7ff-71f204f121ca",
   "metadata": {},
   "source": [
    "## Stop the Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b34f54a0-334b-4033-9ede-5fc84dd72016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n",
      "Error response from daemon: No such container: Llama3-8B-Instruct\n"
     ]
    }
   ],
   "source": [
    "!docker ps -a && \\\n",
    "docker stop Llama3-8B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044a6fb4-0c7d-453e-bd5c-52a66c65b1e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
